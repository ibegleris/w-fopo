{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle as pl\n",
    "import tables\n",
    "import h5py\n",
    "from scipy.constants import c, pi\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from data_plotters_animators import read_variables\n",
    "from functions import *\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import LogNorm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numpy.fft import fftshift\n",
    "from fft_module import *\n",
    "import scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fft(x):\n",
    "    return scipy.fft(x.T).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Conversion_efficiency(object):\n",
    "\n",
    "    def __init__(self, freq_band, possition, filename=None, filepath='',filename2 = 'CE',filepath2 = 'output_final/'):\n",
    "        self.variables = ('P_p', 'P_s', 'f_p', 'f_s','l_p','l_s,' 'P_out', 'P_bef','CE','rounds')\n",
    "        \n",
    "        self.spec, self.fv, self.t, self.P0_p, self.P0_s,self.f_p, self.f_s, self.P_bef,self.ro,U_large,tt =\\\n",
    "            self.load_spectrum('0',filename, filepath)\n",
    "        self.P_max = np.max(w2dbm(self.spec))\n",
    "        \n",
    "        self.spec, self.fv, self.t, self.P0_p, self.P0_s,self.f_p, self.f_s, self.P_bef,self.ro,U_large,tt =\\\n",
    "            self.load_spectrum(possition,filename, filepath)\n",
    "        self.tt = tt\n",
    "       \n",
    "        self.freq_band = freq_band\n",
    "\n",
    "        self.U_large = np.asanyarray(U_large)#[:,:,0]\n",
    "        self.nt = np.shape(self.spec)[0]\n",
    "        self.possition = possition\n",
    "        if possition == '2' or possition == '1':\n",
    "            print('finding signal')\n",
    "            fv_id = self.pos_of_signal()\n",
    "            self.P_in = self.P0_p + self.P0_s\n",
    "        else:\n",
    "            print('finding idler')\n",
    "            fv_id = self.pos_of_idler()\n",
    "            self.P_in = self.P0_p + self.P0_s\n",
    "\n",
    "\n",
    "        lami = 1e-3*c/self.fv[fv_id]\n",
    "        self.lami = lami\n",
    "        self.lamp = 1e-3*c/self.f_p\n",
    "        self.l_s = 1e-3*c/self.f_s\n",
    "        self.U_large_norm =  w2dbm(np.abs(self.U_large)**2) - self.P_max \n",
    "        P_out_vec = []\n",
    "        P_out_vec_casc = []\n",
    "        self.fv_id = fv_id\n",
    "        start, end= self.fv[fv_id] - freq_band, self.fv[fv_id] + freq_band\n",
    "        fv_id_c = self.pos_of_cascade()\n",
    "        start_c, end_c = self.fv[fv_id_c] - freq_band, self.fv[fv_id_c] + freq_band\n",
    "        for i in U_large:\n",
    "            self.spec = np.abs(i)**2\n",
    "            P_out_vec.append(self.calc_P_out(start,end))\n",
    "            P_out_vec_casc.append(self.calc_P_out(start_c,end_c))\n",
    "        self.P_out_vec_casc = np.asanyarray(P_out_vec_casc)\n",
    "        self.P_out_vec = np.asanyarray(P_out_vec)\n",
    "        self.P_out = np.mean(P_out_vec)\n",
    "        self.CE = self.calc_CE()\n",
    "        \n",
    "        self.std = { i : None for i in ('P_p', 'P_s', 'f_p', 'f_s','l_p','l_s,' 'P_out', 'P_bef','CE','rounds')}\n",
    "        self.std['P_out'] = np.std(P_out_vec)\n",
    "        self.std['CE'] = self.std['P_out']*self.CE/self.P_in\n",
    "        \n",
    "        read_write_CE_table(filename2,var = None, P_p = self.P0_p, P_s = self.P0_s, f_p = self.f_p,\n",
    "                                         f_s = self.f_s,P_out = self.P_out,P_bef = self.P_bef, CE = self.CE, var2 = 'CE',std = self.std,file_path=filepath2)\n",
    "        self.spec = np.mean(np.abs(U_large[0:][:])**2, axis = 0)\n",
    "        self.spec = np.abs(U_large[-1][:])**2\n",
    "        self.spec_s = w2dbm(self.spec)-self.P_max \n",
    "        return None\n",
    "\n",
    "    \n",
    "    def pos_of_idler(self):\n",
    "        U_sum = np.sum(np.abs(self.U_large)**2, axis = 0)\n",
    "        fp_id = np.where(U_sum == np.max(U_sum))[0][0]\n",
    "        plom = fp_id+50\n",
    "        fv_id = np.where(U_sum[plom:] == np.max(U_sum[plom:]))[0][0]\n",
    "        fv_id += plom-1\n",
    "        return fv_id\n",
    "    \n",
    "    def pos_of_signal(self):\n",
    "        U_sum = np.sum(np.abs(self.U_large)**2, axis = 0)\n",
    "        fp_id = np.where(U_sum == np.max(U_sum))[0][0]\n",
    "        plom = fp_id - 50\n",
    "        fv_id = np.where(U_sum[:plom] == np.max(U_sum[:plom]))[0][0]\n",
    "        return fv_id+1\n",
    "    \n",
    "    \n",
    "    def pos_of_cascade(self):\n",
    "        sig_id = self.pos_of_signal() - 50\n",
    "        U_sum = np.sum(np.abs(self.U_large)**2, axis = 0)\n",
    "        plom = sig_id\n",
    "        fv_id = np.where(U_sum[:plom] == np.max(U_sum[:plom]))[0][0]\n",
    "        return fv_id\n",
    "    \n",
    "    \n",
    "    def load_spectrum(self, possition,filename='data_large', filepath=''):\n",
    "        with h5py.File(filepath+filename+'.hdf5','r') as f: \n",
    "            l = f.get(possition)\n",
    "            U_large = ()\n",
    "            integers_list = [int(i) for i in l.keys()]\n",
    "            integers_list.sort()\n",
    "            integers_generator = (str(n) for n in integers_list)\n",
    "            for i in integers_generator:\n",
    "                steady_state = i\n",
    "                layers = possition + '/' + steady_state\n",
    "                D = read_variables(filename,layers, filepath)\n",
    "                U = D['U']\n",
    "                U_large += (U,)\n",
    "\n",
    "            fv = D['fv']\n",
    "            ro = D['ro']\n",
    "\n",
    "            Uabs = w2dbm(np.abs(U)**2)\n",
    "            P0_s = D['P0_s']\n",
    "            P0_p = D['P0_p']\n",
    "            t = D['t']\n",
    "            f_p = D['f_p']\n",
    "            f_s = D['f_s']\n",
    "            layers = '1/0'\n",
    "            \n",
    "            D = read_variables(filename,layers, filepath)\n",
    "            Uabss =np.abs(D['U']*(t[1] - t[0]))**2\n",
    "            fvs = D['fv']\n",
    "            tt = D['t']\n",
    "\n",
    "            P_bef = simps(Uabss,fvs)\n",
    "            P_bef /= (2*np.max(tt))\n",
    "            #print(P_bef)\n",
    "        return dbm2w(Uabs), fv,t, P0_p, P0_s, f_p, f_s,P_bef, ro, U_large,t\n",
    "\n",
    "\n",
    "\n",
    "    def calc_P_out(self,start,end):\n",
    "        i = np.where(\n",
    "            np.abs(self.fv - start) == np.min(np.abs(self.fv - start)))[0][0]\n",
    "        j = np.where(\n",
    "            np.abs(self.fv - end) == np.min(np.abs(self.fv - end)))[0][0]\n",
    "        E_out = simps(self.spec[i:j]*(self.tt[1] - self.tt[0])**2, self.fv[i:j])\n",
    "        P_out = E_out/(2*np.max(self.tt))\n",
    "        return P_out   \n",
    "\n",
    "\n",
    "    def calc_CE(self):\n",
    "        CE = 100*self.P_out/ (self.P0_p + self.P0_s)\n",
    "        return CE\n",
    "\n",
    "\n",
    "    \n",
    "    def P_out_round(self,filesave):\n",
    "        \"\"\"Plots the output average power with respect to round trip number\"\"\"\n",
    "        self.l_p = 1e-3*c/self.f_p\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        plt.plot(range(len(self.P_out_vec)), self.P_out_vec)\n",
    "        plt.xlabel('Rounds')\n",
    "        plt.ylabel('Output Power')\n",
    "        plt.title(f\"$P_p=$ {float(CE.P0_p):.{2}} W, $P_s=$ {float(CE.P0_s*1e3):.{2}} mW, $\\\\lambda_p=$ {float(CE.lamp):.{6}} nm,  $\\\\lambda_s=$ {float(CE.l_s):.{6}} nm, maximum output at: {float(CE.lami):.{6}} nm ({float(1e-3*c/CE.lami):.6} Thz)\")\n",
    "        plt.savefig('power_per_round'+filesave+'.png')\n",
    "\n",
    "        data = (range(len(self.P_out_vec)), self.P_out_vec)\n",
    "        _data ={'pump_power':self.P0_p, 'pump_wavelength': self.l_p, 'out_wave': self.lami}\n",
    "        with open('power_per_round'+filesave+'.pickle','wb') as f:\n",
    "            pl.dump(fig,f)\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "\n",
    "    def P_out_round_casc(self,filesave):\n",
    "        \"\"\"Plots the output average power with respect to round trip number\"\"\"\n",
    "        self.l_p = 1e-3*c/self.f_p\n",
    "        fig = plt.figure(figsize=(20,10))\n",
    "        plt.plot(range(len(self.P_out_vec)), self.P_out_vec_casc)\n",
    "        plt.xlabel('Rounds')\n",
    "        plt.ylabel('Output Power')\n",
    "        plt.title(f\"$P_p=$ {float(CE.P0_p):.{2}} W, $P_s=$ {float(CE.P0_s*1e3):.{2}} mW, $\\\\lambda_p=$ {float(CE.lamp):.{6}} nm,  $\\\\lambda_s=$ {float(CE.l_s):.{6}} nm, maximum output at: {float(CE.lami):.{6}} nm ({float(1e-3*c/CE.lami):.6} Thz)\")\n",
    "        plt.savefig('power_per_round_casc'+filesave+'.png')\n",
    "        data = (range(len(self.P_out_vec)), self.P_out_vec)\n",
    "        _data ={'pump_power':self.P0_p, 'pump_wavelength': self.l_p, 'out_wave': self.lami}\n",
    "        with open('power_per_round_casc'+filesave+'.pickle','wb') as f:\n",
    "            pl.dump(fig,f)\n",
    "        plt.clf()\n",
    "        plt.close('all')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_write_CE_table(filename,var = None, P_p = None, P_s = None, f_p = None, f_s = None,P_out = None, P_bef = None,CE = None, var2 = 'CE',std = None,file_path=''):\n",
    "        \n",
    "        \"\"\" Given values of the parameters this function uses pandas to open an\n",
    "            hdf5 file and append to the dataframe there. It also returns the full data\n",
    "            for post-processing. \n",
    "            \n",
    "            It returns a tuple of 2 numpy arrays the first with the variable var and the second with\n",
    "            the conversion efficiencty (as default). If no input is given( default then it just reads the )\n",
    "        \"\"\"\n",
    "        try:\n",
    "            l_s = 1e-3*c/f_s\n",
    "        except TypeError:\n",
    "            l_s = None\n",
    "            pass\n",
    "        try:\n",
    "            l_p = 1e-3*c/f_p\n",
    "        except TypeError:\n",
    "            l_p = None\n",
    "            pass\n",
    "        A = np.array([P_p, P_s, f_p, f_s,l_s,l_p, P_out, P_bef, CE]).T\n",
    "        a = pd.DataFrame(A, index = ['P_p', 'P_s','f_p', 'f_s','l_s','l_p', 'P_out','P_bef', 'CE']).T\n",
    "        try:\n",
    "            ab = pd.read_hdf(file_path+filename+'.hdf5')\n",
    "            if not(A.any() == None):\n",
    "                ab = ab.append(a, ignore_index=True)\n",
    "        except IOError:\n",
    "            if not(A.any() == None):\n",
    "                ab = a\n",
    "            else: \n",
    "                sys.exit(\"There is no data in file or given\")\n",
    "            pass\n",
    "        store = ab.to_hdf(file_path+filename+'.hdf5',key='a')\n",
    "        b = pd.DataFrame.from_dict([std])\n",
    "        try:\n",
    "            ba = pd.read_hdf(file_path+filename+'_std.hdf5', key = 'b')\n",
    "            if not(A.any() == None):\n",
    "                ba = ba.append(b, ignore_index=True)\n",
    "        except IOError:\n",
    "            if not(A.any() == None):\n",
    "                ba = b\n",
    "            else: \n",
    "                sys.exit(\"There is no data in file or given\")\n",
    "            pass\n",
    "        store2 = ba.to_hdf(file_path+filename+'_std.hdf5', key = 'b')\n",
    "\n",
    "        if var is None:\n",
    "            return None\n",
    "        else:\n",
    "            return ab[var].as_matrix(),ab[var2].as_matrix(),ba\n",
    "\n",
    "\n",
    "def plot_CE(var,var2 = 'CE',filename = 'CE', filepath='output_final/', filesave= None):\n",
    "    var_val, CE,std = read_write_CE_table(filename,var,var2 = var2,file_path=filepath)\n",
    "    std = std[var2].as_matrix()\n",
    "    fig = plt.figure(figsize=(20.0, 10.0))\n",
    "    plt.errorbar(var_val, CE, yerr=std, capsize= 10)\n",
    "    plt.gca().get_yaxis().get_major_formatter().set_useOffset(False)\n",
    "    plt.gca().get_xaxis().get_major_formatter().set_useOffset(False)\n",
    "    plt.xlabel(var)\n",
    "    plt.ylabel(var2)\n",
    "    plt.savefig(filesave+'.png',bbox_inches = 'tight')\n",
    "    data = (var_val, CE)\n",
    "    with open(str(filesave)+'.pickle','wb') as f:\n",
    "        pl.dump((fig,data),f)\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def contor_plot(CE,fmin = None,fmax = None,  rounds = None,filename = None):\n",
    "    if not(fmin):\n",
    "        fmin = CE.fv[CE.fv_id] - CE.freq_band\n",
    "    if not(fmax):\n",
    "        fmax = CE.fv[CE.fv_id] + CE.freq_band\n",
    "    print(fmin,fmax)\n",
    "    i = np.where(np.abs(CE.fv - fmin) == np.min(np.abs(CE.fv - fmin)))[0][0]\n",
    "    j = np.where(np.abs(CE.fv - fmax) == np.min(np.abs(CE.fv - fmax)))[0][0]\n",
    "    \n",
    "\n",
    "\n",
    "    if rounds is None:\n",
    "        rounds = np.shape(CE.U_large_norm)[0]\n",
    "   \n",
    "    CE.ro = range(rounds)\n",
    "    x,y = np.meshgrid(CE.ro[:rounds], CE.fv[i:j])\n",
    "    z = CE.U_large_norm[:rounds,i:j].T\n",
    "    #print(np.shape(x), np.shape(z))\n",
    "    #low_values_indices = z < -60  # Where values are low\n",
    "    #z[low_values_indices] = -60  # All low values set to 0\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    plt.contourf(x,y, z, extend = 'min',cmap=plt.cm.jet)\n",
    "    plt.xlabel(r'$rounds$')\n",
    "    plt.ylim(fmin,fmax)\n",
    "    #plt.xlim(0,200)\n",
    "    plt.ylabel(r'$f(THz)$')\n",
    "    plt.colorbar()\n",
    "    l_p = 1e-3*c/CE.f_p\n",
    "    plt.title(f\"$P_p=$ {float(CE.P0_p):.{2}} W, $P_s=$ {float(CE.P0_s*1e3):.{2}} mW, $\\\\lambda_p=$ {float(CE.lamp):.{6}} nm,  $\\\\lambda_s=$ {float(CE.l_s):.{6}} nm, maximum output at: {float(CE.lami):.{6}} nm\")\n",
    "    data = (CE.ro, CE.fv, z )\n",
    "    _data ={'pump_power':CE.P0_p, 'pump_wavelength': l_p, 'out_wave': CE.lami}\n",
    "    if filename is not None:\n",
    "        plt.savefig(str(filename), bbox_inches = 'tight')\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "        #with open(str(filename)+'.pickle','wb') as f:\n",
    "        #    pl.dump((data,_data),f)\n",
    "\n",
    "\n",
    "    else:\n",
    "        plt.show()\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def final_1D_spec(ii,specs):\n",
    "    filename = 'spectrum_fopo_final'\n",
    "    fig = plt.figure(figsize=(20,10))\n",
    "    #fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    ax2 = ax1.twiny()\n",
    "\n",
    "    ax1.plot(specs.fv, specs.spec_s, label = r'$\\lambda_p$='+str(specs.l_p)+r', $\\lambda_s $='+str(specs.l_s))\n",
    "\n",
    "    ax1.set_xlabel(r'$f (THz)$')\n",
    "    ax1.set_ylabel(r'spec (dB)')\n",
    "    #ax1.set_xticks(np.arange(min(specs.fv), max(specs.fv)+1, 10))\n",
    "    #ax1.set_ylim(260,320)\n",
    "    #print(round(min(specs.fv)),round(max(specs.fv)))\n",
    "    #sys.exit()\n",
    "    #ax1.set_xticks(np.arange(round(min(specs.fv)),round(max(specs.fv)),10))\n",
    "    new_tick_locations = ax1.get_xticks()\n",
    "\n",
    "    def tick_function(X):\n",
    "        l = 1e-3*c/X\n",
    "        return [\"%.2f\" % z for z in l]\n",
    "    \n",
    "    ax1.set_ylim(-100,1)\n",
    "    ax2.set_xlim(ax1.get_xlim())\n",
    "    ax2.set_xticks(new_tick_locations)\n",
    "    ax2.set_xticklabels(tick_function(new_tick_locations))\n",
    "    ax2.set_xlabel(r\"$\\lambda (nm)$\")\n",
    "    #plt.ylim(260,320)\n",
    "    ax1.legend()\n",
    "    plt.savefig(filename+str(ii)+'.png', bbox_inches = 'tight')\n",
    "    #plt.show()\n",
    "    with open(filename+str(ii)+'.pickle','wb') as f:\n",
    "        pl.dump(fig,f)\n",
    "    plt.clf()\n",
    "    plt.close('all')\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "#from os.path import , join\n",
    "data_dump =  'output_dump'\n",
    "outside_dirs = [f for f in listdir(data_dump)]\n",
    "inside_dirs = [f for f in listdir(data_dump+ '/'+outside_dirs[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "which = 'output_dump_pump_wavelengths/7w'\n",
    "which = 'output_dump_pump_wavelengths/wrong'\n",
    "which = 'output_dump_pump_wavelengths'\n",
    "#which = 'output_dump_pump_wavelengths/2_rounds'\n",
    "#which ='output_dump_pump_powers/ram0ss0'\n",
    "#which = 'output_dump/'#_pump_powers'\n",
    "which_l = 'output_dump/output'\n",
    "\n",
    "\n",
    "\n",
    "outside_vec = range(len(outside_dirs))\n",
    "#outside_vec = range(1,2)\n",
    "inside_vec = range(len(inside_dirs)- 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "finding signal\n",
      "50.0717369396 630.906520474\n",
      "1048.17107345 1254.71579043\n"
     ]
    }
   ],
   "source": [
    "os.system('mkdir output_final')\n",
    "for ii in outside_vec:\n",
    "    ii = str(ii)\n",
    "    which = which_l+ ii\n",
    "    os.system('rm output_final/CE.hdf5 output_final/CE_std.hdf5')\n",
    "    os.system('mkdir output_final/'+str(ii))\n",
    "\n",
    "    for i in inside_vec:\n",
    "        print(ii,i)\n",
    "        CE = Conversion_efficiency(2,possition = '2', filename = 'data_large',filepath = which+'/output'+str(i)+'/data/')\n",
    "        fmin,fmax,rounds  = 310,330,2000#np.min(CE.fv),np.max(CE.fv),None\n",
    "        fmin,fmax,rounds = None, None, None\n",
    "        fmin,fmax,rounds = np.min(CE.fv),np.max(CE.fv), None\n",
    "        \n",
    "\n",
    "        contor_plot(CE,fmin,fmax,rounds,filename= str(ii)+'_'+str(i))\n",
    "        CE.P_out_round(filesave = str(ii)+'_'+str(i))\n",
    "        CE.P_out_round_casc(filesave = str(ii)+'_'+str(i))\n",
    "        final_1D_spec(i,CE)\n",
    "        print(1e-3*c/CE.f_p, CE.lami)\n",
    "        \n",
    "        del CE\n",
    "        gc.collect()\n",
    "    #var1, var2 = 'P_bef', 'P_out'\n",
    "    for var1,var2 in (('P_p', 'P_out'), ('P_p', 'CE')):\n",
    "        plot_CE(var1, var2,filesave = 'output_final/'+str(ii)+'/'+var2+str(ii))  \n",
    "    #sys.exit()\n",
    "    os.system('mv *png output_final/'+str(ii))\n",
    "    os.system('mv *pickle output_final/'+str(ii))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CE\n"
     ]
    }
   ],
   "source": [
    "for ii in outside_vec:\n",
    "    for i in inside_vec:\n",
    "\n",
    "        \n",
    "        print(var2)\n",
    "            \n",
    "\n",
    "        os.system('mv *png output_final/'+str(ii))\n",
    "        os.system('mv *pickle output_final/'+str(ii))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "ii = str(0)\n",
    "os.system('mv *png output_final/'+ii)\n",
    "os.system('mv *pickle output_final/'+ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "nbpresent": {
   "slides": {},
   "themes": {
    "default": "76a933dd-2b7a-4539-97ef-87229f33bd0b",
    "theme": {}
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
